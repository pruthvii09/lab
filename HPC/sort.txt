#include <iostream>   // For input and output (cin, cout)
#include <ctime>      // For measuring CPU time for performance comparison
#include <cstdlib>    // For generating random numbers (rand, srand)
#include <omp.h>      // For OpenMP parallel programming

using namespace std;

// ---------------------- Bubble Sort (Sequential) ---------------------- //
// Simple Bubble Sort algorithm: repeatedly steps through the list,
// compares adjacent elements, and swaps them if they are in the wrong order.
void bubbleSort(int arr[], int n)
{
    for (int i = 0; i < n - 1; ++i) // Outer loop for passes
    {
        for (int j = 0; j < n - i - 1; ++j) // Inner loop for comparisons
        {
            if (arr[j] > arr[j + 1])
            {
                swap(arr[j], arr[j + 1]); // Swap if elements are out of order
            }
        }
    }
}

// ---------------------- Merge Function for Merge Sort ---------------------- //
// Merges two sorted halves into one sorted array
void merge(int arr[], int l, int m, int r)
{
    // Calculate sizes of two subarrays to merge
    int n1 = m - l + 1;
    int n2 = r - m;

    // Create temporary arrays to hold elements
    int *L = new int[n1];
    int *R = new int[n2];

    // Copy data to temporary arrays L[] and R[]
    for (int i = 0; i < n1; ++i)
        L[i] = arr[l + i];
    for (int j = 0; j < n2; ++j)
        R[j] = arr[m + 1 + j];

    // Merge the temporary arrays back into arr[l..r]
    int i = 0, j = 0, k = l;
    while (i < n1 && j < n2)
    {
        if (L[i] <= R[j])
        {
            arr[k++] = L[i++];
        }
        else
        {
            arr[k++] = R[j++];
        }
    }

    // Copy any remaining elements of L[], if any
    while (i < n1)
        arr[k++] = L[i++];

    // Copy any remaining elements of R[], if any
    while (j < n2)
        arr[k++] = R[j++];

    // Free the dynamically allocated memory
    delete[] L;
    delete[] R;
}

// ---------------------- Merge Sort (Recursive, Parallelizable) ---------------------- //
// Recursive function to sort an array using Merge Sort algorithm
// OpenMP parallel sections are used to parallelize left and right halves sorting
void mergeSort(int arr[], int l, int r)
{
    if (l < r)
    {
        int m = l + (r - l) / 2; // Find the middle point

        // Parallelize the two recursive calls for left and right subarrays
        #pragma omp parallel sections
        {
            #pragma omp section
            {
                mergeSort(arr, l, m); // Sort first half
            }
            #pragma omp section
            {
                mergeSort(arr, m + 1, r); // Sort second half
            }
        }

        // Merge the sorted halves
        merge(arr, l, m, r);
    }
}

// ---------------------- Print Array ---------------------- //
// Utility function to print the elements of the array
void printArray(int arr[], int size)
{
    for (int i = 0; i < size; ++i)
        cout << arr[i] << " ";
    cout << endl;
}

// ---------------------- Main Function ---------------------- //
int main()
{
    int n;
    cout << "Enter the size of the array: ";
    cin >> n; // Input the size of the array

    // Dynamically allocate an array of size n and fill it with random numbers
    int *arr = new int[n];
    srand(time(0)); // Seed for random number generation
    for (int i = 0; i < n; ++i)
        arr[i] = rand() % 100; // Random numbers between 0 and 99

    // ------------- Sequential Bubble Sort ------------- //
    clock_t start = clock(); // Record start time
    bubbleSort(arr, n); // Perform bubble sort
    clock_t end = clock(); // Record end time
    double sequentialBubbleTime = double(end - start) / CLOCKS_PER_SEC; // Calculate time in seconds

    // ------------- Parallel Bubble Sort (Ineffective) ------------- //
    // Parallel bubble sort using OpenMP (not effective because multiple threads redo the same work)
    start = clock();
    #pragma omp parallel
    {
        bubbleSort(arr, n); // ⚠️ Each thread independently performs the full bubble sort (redundant work)
    }
    end = clock();
    double parallelBubbleTime = double(end - start) / CLOCKS_PER_SEC;

    // ------------- Sequential Merge Sort ------------- //
    start = clock();
    mergeSort(arr, 0, n - 1); // Perform merge sort (internally parallel sections are present)
    end = clock();
    double sequentialMergeTime = double(end - start) / CLOCKS_PER_SEC;

    // ------------- Parallel Merge Sort ------------- //
    // Parallel merge sort using OpenMP tasks
    start = clock();
    #pragma omp parallel
    {
        #pragma omp single // Only one thread initiates the first call
        {
            mergeSort(arr, 0, n - 1); // Recursive calls internally parallelized
        }
    }
    end = clock();
    double parallelMergeTime = double(end - start) / CLOCKS_PER_SEC;

    // ------------- Display Time Comparison ------------- //
    cout << "\n--- Sorting Time Comparison ---\n";
    cout << "Sequential Bubble Sort Time: " << sequentialBubbleTime << " seconds" << endl;
    cout << "Parallel Bubble Sort Time: " << parallelBubbleTime << " seconds" << endl;
    cout << "Sequential Merge Sort Time: " << sequentialMergeTime << " seconds" << endl;
    cout << "Parallel Merge Sort Time: " << parallelMergeTime << " seconds" << endl;

    // Free the dynamically allocated memory to prevent memory leaks
    delete[] arr;

    return 0; // Successful program termination
}









1. Why is Bubble Sort parallelization ineffective in your code?
Answer:
Because each thread is doing the same bubble sort work independently on the same array.
They are not dividing the work among themselves — so there is no real speedup, just redundant computation.

2. Why is Merge Sort better suited for parallelization?
Answer:
Merge Sort naturally divides the array into two halves.
Each half can be sorted independently and in parallel, making it very suitable for divide-and-conquer parallelism using OpenMP.

3. What is the time complexity of Bubble Sort and Merge Sort?
Answer:

Bubble Sort: O(n²) in worst and average case.

Merge Sort: O(n log n) in all cases (best, average, worst).

4. What does #pragma omp parallel sections do?
Answer:
It tells OpenMP to split different sections (like two recursive mergeSort calls) into separate threads and execute them in parallel.

5. What does #pragma omp single mean in your program?
Answer:
It tells OpenMP to let only one thread (out of many) execute the next block of code (starting the first mergeSort call).
After that, the recursion itself handles parallel work.

6. What are the advantages of Merge Sort compared to Bubble Sort?
Answer:

Merge Sort is faster (O(n log n) vs O(n²)).

Merge Sort can handle larger arrays efficiently.

Merge Sort is stable and parallelizable.

7. What are the disadvantages of Merge Sort?
Answer:

Merge Sort needs extra memory for temporary arrays (O(n) space complexity).

Slightly more complex to implement compared to Bubble Sort.

8. Why do we use srand(time(0)) before generating random numbers?
Answer:
srand(time(0)) initializes the random number generator with the current time, so that different random numbers are generated every time you run the program.

9. Why do we use delete[] arr at the end of the program?
Answer:
Because arr was allocated dynamically with new, and if we don't free it with delete[], it would cause a memory leak.